{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys \n",
    "import torch \n",
    "import datetime\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import IPython.display as ipd\n",
    "from argparse import Namespace\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import argparse\n",
    "import scipy \n",
    "from IPython.display import Audio\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import cm\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __config__ import *\n",
    "import attentional_control.dnn.models.simplified_tasnet as simplified_tasnet\n",
    "import attentional_control.dnn.losses.sisdr as sisdr_lib\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_model_requirements(model, opt,\n",
    "                           number_of_batches=10,\n",
    "                           batch_size=1,\n",
    "                           n_sources=2,\n",
    "                           time_length=32000,\n",
    "                           fs=8000,\n",
    "                           to_GPU=True):\n",
    "    \n",
    "    per_sec_c = number_of_batches * batch_size * n_sources * (time_length / (1. * fs))\n",
    "    \n",
    "    def random_input_gen(number_of_batches, batch_size, n_sources, time_length):\n",
    "        for i in range(number_of_batches):\n",
    "            sources = torch.rand(batch_size, n_sources, time_length)\n",
    "            mixture = torch.sum(sources, dim=1)\n",
    "            yield mixture, sources\n",
    "            \n",
    "    requirements_dict = {\n",
    "        'Fetching': 0.,\n",
    "        'Moving to GPU': 0.,\n",
    "        'Train Forward': 0.,\n",
    "        'Eval Forward': 0.,\n",
    "        'Loss Computation': 0.,\n",
    "        'Backward': 0.,\n",
    "        'Parameters': 0.,\n",
    "    }\n",
    "\n",
    "    numparams = 0\n",
    "    for f in model.parameters():\n",
    "        if f.requires_grad:\n",
    "            numparams += f.numel()\n",
    "    requirements_dict['Parameters'] = numparams\n",
    "            \n",
    "    if to_GPU:\n",
    "        model = model.cuda()\n",
    "\n",
    "    sisdr_loss = sisdr_lib.PermInvariantSISDR(batch_size=batch_size,\n",
    "                                              n_sources=n_sources,\n",
    "                                              zero_mean=True,\n",
    "                                              backward_loss=False,\n",
    "                                              improvement=True,\n",
    "                                              return_individual_results=False)\n",
    "\n",
    "    train_gen = random_input_gen(number_of_batches, batch_size, n_sources, time_length)\n",
    "    test_gen = random_input_gen(number_of_batches, batch_size, n_sources, time_length)\n",
    "\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for data in tqdm(train_gen, desc='Training'):\n",
    "        st = time.time()\n",
    "        opt.zero_grad()\n",
    "        m1wavs = data[0].unsqueeze(1)\n",
    "        clean_wavs = data[-1]\n",
    "        requirements_dict['Fetching'] += (time.time() - st) / per_sec_c\n",
    "        \n",
    "        st = time.time()\n",
    "        if to_GPU:\n",
    "            m1wavs = m1wavs.cuda()\n",
    "            clean_wavs = clean_wavs.cuda()\n",
    "        requirements_dict['Moving to GPU'] += (time.time() - st) / per_sec_c\n",
    "        \n",
    "        st = time.time()\n",
    "        rec_sources_wavs = model(m1wavs)\n",
    "        requirements_dict['Train Forward'] += (time.time() - st) / per_sec_c\n",
    "\n",
    "        st = time.time()\n",
    "        l = sisdr_loss(rec_sources_wavs, clean_wavs, initial_mixtures=m1wavs)\n",
    "        requirements_dict['Loss Computation'] += (time.time() - st) / per_sec_c\n",
    "        \n",
    "        st = time.time()\n",
    "        l.backward()\n",
    "        opt.step()\n",
    "        requirements_dict['Backward'] += (time.time() - st) / per_sec_c\n",
    "        \n",
    "        \n",
    "    del model\n",
    "    return requirements_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 3it [02:00, 39.41s/it]"
     ]
    }
   ],
   "source": [
    "computational_results = {}\n",
    "\n",
    "for P, R in [(3, 4), (3, 1), (3, 2), (61, 4), (61, 2), (61, 1)]:\n",
    "    for to_GPU in [False, True]:\n",
    "        hparams = {\n",
    "            'B': 256,\n",
    "            'H': 512,\n",
    "            'P': P,\n",
    "            'R': R,\n",
    "            'X': 8,\n",
    "            'L': 21,\n",
    "            'N': 64,\n",
    "            'S': 2,\n",
    "            'lr': 0.001,\n",
    "        }\n",
    "\n",
    "        model = simplified_tasnet.TDCN(\n",
    "            B=hparams['B'],\n",
    "            H=hparams['H'],\n",
    "            P=hparams['P'],\n",
    "            R=hparams['R'],\n",
    "            X=hparams['X'],\n",
    "            L=hparams['L'],\n",
    "            N=hparams['N'],\n",
    "            S=hparams['S'])\n",
    "\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=hparams['lr'])\n",
    "\n",
    "        reqs = get_model_requirements(model, opt, \n",
    "                                      number_of_batches=10,\n",
    "                                      batch_size=1,\n",
    "                                      n_sources=2,\n",
    "                                      time_length=32000,\n",
    "                                      to_GPU=to_GPU)\n",
    "        \n",
    "        computational_results['P_{}_R_{}_GPU_{}'.format(P, R, to_GPU)] = reqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(computational_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
